Run the following Commands in CloudShell
curl -LO raw.githubusercontent.com/QUICK-GCP-LAB/2-Minutes-Labs-Solutions/main/Analyzing%20Findings%20with%20Security%20Command%20Center/gsp1164-1.sh

sudo chmod +x gsp1164-1.sh

./gsp1164-1.sh
Go to Export to Pub/Sub from here

For the continuous export name, enter in export-findings-pubsub.

Run again the following Commands in CloudShell
export ZONE=
curl -LO raw.githubusercontent.com/QUICK-GCP-LAB/2-Minutes-Labs-Solutions/main/Analyzing%20Findings%20with%20Security%20Command%20Center/gsp1164-2.sh

sudo chmod +x gsp1164-2.sh

./gsp1164-2.sh
bq query --apilog=/dev/null --use_legacy_sql=false  \
"SELECT finding_id,event_time,finding.category FROM continuous_export_dataset.findings"
NOW FOLLOW VIDEO'S INSTRUCTIONS

Got to Create a bucket from here

for BUCKET NAME type scc-export-bucket-YOUR_PROJECT_ID

Now go to Export findings to Cloud Storage from here

Set the filename to findings.jsonl

Go to BigQuery Studio from here

Set the TABLE NAME to old_findings

Now paste in the following schema

[   
  {
    "mode": "NULLABLE",
    "name": "resource",
    "type": "JSON"
  },   
  {
    "mode": "NULLABLE",
    "name": "finding",
    "type": "JSON"
  }
]
